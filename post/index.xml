<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on SunGeng Blog</title>
    <link>https://sungenglab.github.io/post/</link>
    <description>Recent content in Posts on SunGeng Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 28 Apr 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://sungenglab.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>高性能计算基础知识</title>
      <link>https://sungenglab.github.io/post/2024-04-28%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Sun, 28 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://sungenglab.github.io/post/2024-04-28%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80/</guid>
      <description>1. 半精度浮点数FP16各个部分的具体位数，为什么要有半精度浮点数？ 半精度浮点数（FP16）是一种使用16位（2字节）来表示的浮点数格式。在这</description>
    </item>
    <item>
      <title>Hello World</title>
      <link>https://sungenglab.github.io/post/firsttry/</link>
      <pubDate>Sat, 27 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://sungenglab.github.io/post/firsttry/</guid>
      <description></description>
    </item>
    <item>
      <title>深入理解Pytorch源码中的CUDA算子01-ReduceSum</title>
      <link>https://sungenglab.github.io/post/2024-04-27pytorch%E7%AE%97%E5%AD%90%E5%88%86%E6%9E%90/</link>
      <pubDate>Sat, 27 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://sungenglab.github.io/post/2024-04-27pytorch%E7%AE%97%E5%AD%90%E5%88%86%E6%9E%90/</guid>
      <description></description>
    </item>
  </channel>
</rss>
